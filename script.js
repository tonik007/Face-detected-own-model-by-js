// const imageUpload = document.getElementById('imageUpload');
// const status = document.getElementById('status');
// const imageContainer = document.getElementById('imageContainer');

// Promise.all([
//   faceapi.nets.tinyFaceDetector.loadFromUri('models'),
//   faceapi.nets.faceLandmark68Net.loadFromUri('models'),
//   faceapi.nets.faceRecognitionNet.loadFromUri('models'),
//   faceapi.nets.ssdMobilenetv1.loadFromUri('models')
// ]).then(() => {
//   status.innerText = "âœ… Models loaded. Upload your image.";
// }).catch(err => {
//   status.innerText = "âŒ Model load failed";
//   console.error(err);
// });

// imageUpload.addEventListener('change', async () => {
//   const imageFile = imageUpload.files[0];
//   if (!imageFile) return;
  
  

//   const image = await faceapi.bufferToImage(imageFile);

//   imageContainer.innerHTML = '';
//   status.innerText = 'ðŸ” Detecting...';
//   imageContainer.appendChild(image);

//   const canvas = faceapi.createCanvasFromMedia(image);
//   imageContainer.appendChild(canvas);
//   const displaySize = { width: image.width, height: image.height };
//   faceapi.matchDimensions(canvas, displaySize);

//   const labeledDescriptors = await loadLabeledImages();
//   const faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);

//   const detections = await faceapi
//     .detectAllFaces(image)
//     .withFaceLandmarks()
//     .withFaceDescriptors();

//   if (!detections.length) {
//     status.innerText = "ðŸ˜• No face detected.";
//     return;
//   }

//   const resized = faceapi.resizeResults(detections, displaySize);
//   const results = resized.map(d => faceMatcher.findBestMatch(d.descriptor));

//   results.forEach((result, i) => {
//     const box = resized[i].detection.box;
//     const drawBox = new faceapi.draw.DrawBox(box, { label: result.toString() });
//     drawBox.draw(canvas);

//     if (!result.label.includes('unknown')) {
//       status.innerText = `âœ… Image person Named ${result.label}`;
//     } else {
//       status.innerText = 'ðŸš« Unknown Face';
//     }
//   });
// });

// function loadLabeledImages() {
//   const labels = ['Tonik', 'Cristiano Rolando']; // à¦«à§‹à¦²à§à¦¡à¦¾à¦° à¦¨à¦¾à¦®
//   return Promise.all(
//     labels.map(async label => {
//       const descriptions = [];
//       for (let i = 1; i <= 2; i++) {
//         const imgPath = `labeled_images/${label}/${i}.jpg`;
//         try {
//           const img = await faceapi.fetchImage(imgPath);
//           const detection = await faceapi
//             .detectSingleFace(img)
//             .withFaceLandmarks()
//             .withFaceDescriptor();
//           if (detection) {
//             descriptions.push(detection.descriptor);
//           } else {
//             console.warn(`No face found in ${imgPath}`);
//           }
//         } catch (err) {
//           console.error(`Failed to load ${imgPath}:`, err);
//         }
//       }
//       return new faceapi.LabeledFaceDescriptors(label, descriptions);
//     })
//   );
// }


const imageUpload = document.getElementById('imageUpload');
const status = document.getElementById('status');
const imageContainer = document.getElementById('imageContainer');

// à¦®à¦¡à§‡à¦² à¦²à§‹à¦¡
async function loadModels() {
  try {
    await Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri('models'),
      faceapi.nets.faceLandmark68Net.loadFromUri('models'),
      faceapi.nets.faceRecognitionNet.loadFromUri('models'),
      faceapi.nets.ssdMobilenetv1.loadFromUri('models'),
    ]);
    status.innerText = "âœ… Models loaded. Upload your image.";
  } catch (error) {
    status.innerText = "âŒ Model load failed";
    console.error(error);
  }
}

// à¦›à¦¬à¦¿ à¦†à¦ªà¦²à§‹à¦¡ à¦‡à¦­à§‡à¦¨à§à¦Ÿ à¦¹à§à¦¯à¦¾à¦¨à§à¦¡à¦²à¦¾à¦°
async function onImageUpload() {
  const imageFile = imageUpload.files[0];
  if (!imageFile) return;

  // à¦†à¦—à§‡à¦° à¦›à¦¬à¦¿ à¦“ à¦•à§à¦¯à¦¾à¦¨à¦­à¦¾à¦¸ à¦®à§à¦›à§‡ à¦«à§‡à¦²
  imageContainer.innerHTML = '';
  status.innerText = 'â³ Loading image...';

  try {
    // à¦«à¦¾à¦‡à¦² à¦¥à§‡à¦•à§‡ image element à¦¬à¦¾à¦¨à¦¾à¦“
    const image = await faceapi.bufferToImage(imageFile);

    // à¦®à§à¦¯à¦¾à¦•à§à¦¸ à¦¸à¦¾à¦‡à¦œ à¦¸à§‡à¦Ÿà¦¿à¦‚à¦¸
    const MAX_WIDTH = 600;
    const MAX_HEIGHT = 450;

    let width = image.width;
    let height = image.height;

    // aspect ratio à¦§à¦°à§‡ à¦°à§‡à¦–à§‡ à¦¸à¦¾à¦‡à¦œ à¦•à¦®à¦¾à¦“ à¦¯à¦¦à¦¿ à¦¬à§œ à¦¹à§Ÿ
    if (width > MAX_WIDTH || height > MAX_HEIGHT) {
      const widthRatio = MAX_WIDTH / width;
      const heightRatio = MAX_HEIGHT / height;
      const scale = Math.min(widthRatio, heightRatio);
      width = width * scale;
      height = height * scale;
    }

    // à¦¨à¦¤à§à¦¨ à¦¸à¦¾à¦‡à¦œ image element à¦ à¦¸à§‡à¦Ÿ à¦•à¦°à§‹
    image.width = width;
    image.height = height;

    imageContainer.appendChild(image);

    // canvas à¦¤à§ˆà¦°à¦¿ à¦•à¦°à§‹ à¦“ container à¦ à¦¯à§‹à¦— à¦•à¦°à§‹
    const canvas = faceapi.createCanvasFromMedia(image);
    imageContainer.appendChild(canvas);

    // canvas à¦“ display size à¦®à¦¿à¦²à¦¿à§Ÿà§‡ à¦¦à¦¾à¦“
    const displaySize = { width, height };
    faceapi.matchDimensions(canvas, displaySize);

    status.innerText = 'ðŸ” Detecting faces...';

    // à¦²à§‡à¦¬à§‡à¦²à§à¦¡ à¦‡à¦®à§‡à¦œ à¦²à§‹à¦¡ à¦•à¦°à§‹
    const labeledDescriptors = await loadLabeledImages();
    const faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);

    // detection à¦•à¦°à§‹
    const detections = await faceapi
      .detectAllFaces(image)
      .withFaceLandmarks()
      .withFaceDescriptors();

    if (!detections.length) {
      status.innerText = "ðŸ˜• No face detected.";
      return;
    }

    // detect à¦—à§à¦²à§‹ à¦¸à§à¦•à§‡à¦² à¦•à¦°à§‹ display size à¦…à¦¨à§à¦¯à¦¾à§Ÿà§€
    const resizedDetections = faceapi.resizeResults(detections, displaySize);

    // à¦®à§à¦¯à¦¾à¦š à¦–à§à¦à¦œà§‡ à¦¬à§‡à¦° à¦•à¦°à§‹
    const results = resizedDetections.map(d => faceMatcher.findBestMatch(d.descriptor));

    // detect box à¦“ à¦²à§‡à¦¬à§‡à¦² à¦¡à§à¦° à¦•à¦°à§‹
    results.forEach((result, i) => {
      const box = resizedDetections[i].detection.box;
      const drawBox = new faceapi.draw.DrawBox(box, { label: result.toString() });
      drawBox.draw(canvas);

      if (!result.label.includes('unknown')) {
        status.innerText = `âœ… Image person Named ${result.label}`;
      } else {
        status.innerText = 'ðŸš« Unknown Face';
      }
    });

  } catch (error) {
    status.innerText = 'âŒ Error processing image';
    console.error(error);
  }
}

// à¦²à§‡à¦¬à§‡à¦²à§à¦¡ à¦‡à¦®à§‡à¦œ à¦²à§‹à¦¡à¦¾à¦° à¦«à¦¾à¦‚à¦¶à¦¨
async function loadLabeledImages() {
  const labels = ['Tonik', 'Cristiano Rolando', 'Mohsin']; // à¦¤à§‹à¦®à¦¾à¦° à¦²à§‡à¦¬à§‡à¦²à§à¦¡ à¦«à§‹à¦²à§à¦¡à¦¾à¦°à§‡à¦° à¦¨à¦¾à¦®à¦—à§à¦²à§‹
  return Promise.all(
    labels.map(async label => {
      const descriptions = [];
      for (let i = 1; i <= 2; i++) {
        const imgPath = `labeled_images/${label}/${i}.jpg`;
        try {
          const img = await faceapi.fetchImage(imgPath);
          const detection = await faceapi
            .detectSingleFace(img)
            .withFaceLandmarks()
            .withFaceDescriptor();

          if (detection) {
            descriptions.push(detection.descriptor);
          } else {
            console.warn(`No face found in ${imgPath}`);
          }
        } catch (error) {
          console.error(`Failed to load ${imgPath}`, error);
        }
      }
      return new faceapi.LabeledFaceDescriptors(label, descriptions);
    })
  );
}

// à¦®à¦¡à§‡à¦² à¦²à§‹à¦¡ à¦¹à§Ÿà§‡ à¦—à§‡à¦²à§‡ à¦›à¦¬à¦¿ à¦†à¦ªà¦²à§‹à¦¡à§‡à¦° listener à¦¸à§‡à¦Ÿ à¦•à¦°à§‹
loadModels().then(() => {
  imageUpload.addEventListener('change', onImageUpload);
});

